# GPT-OSS CLI Chat Configuration
# Using the actual gpt-oss-20b model from HuggingFace

# Model Configuration
MODEL_NAME=mlx-community/gpt-oss-20b-MXFP4-Q8
QUANTIZATION=int4
DEVICE=auto
MAX_MODEL_LEN=4096
LAZY_LOAD=true
WARMUP=false
TRUST_REMOTE_CODE=true

# HuggingFace Cache Directory (where models are downloaded)
# This sets the cache to /Volumes/tkr-riffic/@tkr-projects/tkr-gpt-oss-20b/models
HF_HOME=/Volumes/tkr-riffic/@tkr-projects/tkr-gpt-oss-20b/models

# Inference Configuration
TEMPERATURE=0.7
TOP_P=0.9
TOP_K=50
REPETITION_PENALTY=1.0
MAX_TOKENS=512
STREAMING=true

# CLI Configuration
COLORIZE=true
SHOW_TOKENS=true
SHOW_LATENCY=true
VERBOSE=false
AUTO_SAVE=false
HISTORY_FILE=.chat_history/.conversation.json
ENABLE_AUTOCOMPLETE=true
MULTILINE_INPUT=true

# Logging
LOG_LEVEL=INFO
